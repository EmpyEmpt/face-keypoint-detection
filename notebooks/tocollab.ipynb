{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import dlib\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python.data import AUTOTUNE\n",
    "import yaml\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=open('../secrets/wandb_key.txt', 'r').read(), relogin=True)\n",
    "config = yaml.safe_load(open('../config.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 192\n",
    "data_dir = '../data/'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..src.dataset import create_dataset, compress_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=config['wandb']['project'],\n",
    "           name='Dataset',\n",
    "           config=config):\n",
    "    i, k = create_dataset(dataset_path=data_dir, image_size=image_size)\n",
    "    compress_splits(i,k, '../data/')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = fetch_ds(config, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from src.data_tests import pass_tests_before_fitting\n",
    "from src.model import compile_model\n",
    "from src.dataset import fetch_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=config['wandb']['project'],\n",
    "           name=config['wandb']['name'],\n",
    "           config=config):\n",
    "    model = compile_model(\n",
    "        input_shape=config['img_shape'], output_shape=config['kp_shape'])\n",
    "\n",
    "    callbacks = [EarlyStopping(**config['callbacks']['EarlyStopping']),\n",
    "                ReduceLROnPlateau(**config['callbacks']['ReduceLROnPlateau']),\n",
    "                WandbCallback(**config['callbacks']['WandbCallback'])]\n",
    "\n",
    "    # data tests (pre-fitting)\n",
    "    pass_tests_before_fitting(\n",
    "        data=train_dataset, img_shape=config['img_shape'], keypoint_shape=config['kp_shape'])\n",
    "    pass_tests_before_fitting(\n",
    "        data=test_dataset, img_shape=config['img_shape'],  keypoint_shape=config['kp_shape'])\n",
    "\n",
    "    # training\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=config['train']['epochs'], validation_data=test_dataset, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "from src.data_tests import pass_tests_before_fitting\n",
    "from src.model import compile_model\n",
    "from src.dataset import fetch_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..optimization import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(config, model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
