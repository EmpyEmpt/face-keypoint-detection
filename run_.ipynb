{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_whole_csv(path):\n",
    "    file = open(path)\n",
    "    csvreader = csv.reader(file)\n",
    "    all = []\n",
    "    next(csvreader, None)\n",
    "    for row in csvreader:\n",
    "        ye = True\n",
    "        for value in row:\n",
    "            if value.startswith('-'):\n",
    "                ye = False\n",
    "                break\n",
    "        if ye:\n",
    "            all.append([row[0], [int(row[1]), int(row[2])],\n",
    "                       int(row[3]) - int(row[1]), row[5:]])\n",
    "    file.close()\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(image, x, y, w, h):\n",
    "    image = image[y:y + h, x:x + w]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(dp):\n",
    "    wh = int(dp[2])\n",
    "    points = [(float(a) / wh) for a in dp[3]]\n",
    "    # crop out face from image\n",
    "    image = cv2.imread(cfg.IMAGES_PATH + dp[0])\n",
    "    image = crop_face(image, int(dp[1][0]), int(dp[1][1]), wh, wh)\n",
    "\n",
    "    # resize image to xxx * xxx\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((cfg.CROP_SIZE, cfg.CROP_SIZE))\n",
    "    image = np.array(image)\n",
    "\n",
    "    # (should I really convert it to tensor?)\n",
    "    points = tf.convert_to_tensor(points, dtype=tf.float32)\n",
    "\n",
    "    # PROFIT?\n",
    "    return image, points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prep_image_old(dp):\n",
    "#     image_path = dp[0]\n",
    "#     bb = dp[1]\n",
    "#     wh = dp[2]\n",
    "#     points = dp[3]\n",
    "#     # crop out face from image\n",
    "#     image = cv2.imread(cfg.IMAGES_PATH + image_path)\n",
    "#     image = crop_face(image, int(\n",
    "#         bb[0]), int(bb[1]), int(wh), int(wh))\n",
    "#     path = 'data\\data\\\\tmp\\\\' + image_path\n",
    "#     cv2.imwrite(path, image)\n",
    "\n",
    "#     # resize image to xxx * xxx\n",
    "#     image = Image.open(path)\n",
    "#     image = image.resize((194, 194))\n",
    "\n",
    "#     path = 'data\\data\\\\croped\\\\' + image_path\n",
    "#     image.save(path)\n",
    "#     # save resize ratio\n",
    "#     crop_r = cfg.CROP_SIZE / wh\n",
    "\n",
    "#     # resize points using resize ratio\n",
    "#     for point in points:\n",
    "#         point = float(point)\n",
    "#         point = point * crop_r\n",
    "\n",
    "#     # convert points to relative [0.0 -> 1]\n",
    "#     npo = []\n",
    "#     for point in points:\n",
    "#         point_ = float(point) / wh\n",
    "#         npo.append(point_)\n",
    "\n",
    "#     # (should I really convert it to tensor?)\n",
    "#     npo = tf.convert_to_tensor(npo, dtype=tf.float32)\n",
    "\n",
    "#     # PROFIT?\n",
    "#     return path, npo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = read_whole_csv(cfg.LABELS_PATH)\n",
    "ds = pd.DataFrame(ds)\n",
    "train_ds, test_ds = split_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old\n",
    "# trainX = []\n",
    "# trainY = []\n",
    "# testX = []\n",
    "# testY = []\n",
    "\n",
    "# for i in range(train_ds.shape[0]):\n",
    "#     path, points = prep_image_old(train_ds.iloc[i])\n",
    "#     input_image = tf.io.read_file(path)\n",
    "#     input_image = tf.image.decode_image(input_image)\n",
    "#     input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "#     trainX.append(input_image)\n",
    "#     trainY.append(points)\n",
    "\n",
    "#     # VERY TEMPOPARY BREAK\n",
    "#     # break\n",
    "\n",
    "# for i in range(test_ds.shape[0]):\n",
    "#     path, points = prep_image_old(train_ds.iloc[i])\n",
    "#     input_image = tf.io.read_file(path)\n",
    "#     input_image = tf.image.decode_image(input_image)\n",
    "#     input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "#     testX.append(input_image)\n",
    "#     testY.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX_ = tf.convert_to_tensor(trainX, dtype=tf.float32) / 255\n",
    "# trainY_ = tf.convert_to_tensor(trainY, dtype=tf.float32)\n",
    "\n",
    "# testX_ = tf.convert_to_tensor(testX, dtype=tf.float32) / 255\n",
    "# testY_ = tf.convert_to_tensor(testY, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GigaFolder\\face_segmentaion\\run_.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000009?line=4'>5</a>\u001b[0m testY \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000009?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(train_ds\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000009?line=7'>8</a>\u001b[0m     image, points \u001b[39m=\u001b[39m prep_image(train_ds\u001b[39m.\u001b[39;49miloc[i])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000009?line=8'>9</a>\u001b[0m     input_image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(image, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000009?line=9'>10</a>\u001b[0m     trainX\u001b[39m.\u001b[39mappend(input_image)\n",
      "\u001b[1;32md:\\GigaFolder\\face_segmentaion\\run_.ipynb Cell 5'\u001b[0m in \u001b[0;36mprep_image\u001b[1;34m(dp)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000016?line=2'>3</a>\u001b[0m points \u001b[39m=\u001b[39m [(\u001b[39mfloat\u001b[39m(a) \u001b[39m/\u001b[39m wh) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m dp[\u001b[39m3\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000016?line=3'>4</a>\u001b[0m \u001b[39m# crop out face from image\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000016?line=4'>5</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(cfg\u001b[39m.\u001b[39;49mIMAGES_PATH \u001b[39m+\u001b[39;49m dp[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000016?line=5'>6</a>\u001b[0m image \u001b[39m=\u001b[39m crop_face(image, \u001b[39mint\u001b[39m(dp[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]), \u001b[39mint\u001b[39m(dp[\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]), wh, wh)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GigaFolder/face_segmentaion/run_.ipynb#ch0000016?line=7'>8</a>\u001b[0m \u001b[39m# resize image to xxx * xxx\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# new\n",
    "trainX = []\n",
    "trainY = []\n",
    "testX = []\n",
    "testY = []\n",
    "\n",
    "for i in range(train_ds.shape[0]):\n",
    "    image, points = prep_image(train_ds.iloc[i])\n",
    "    input_image = tf.cast(image, dtype=tf.int32)\n",
    "    trainX.append(input_image)\n",
    "    trainY.append(points)\n",
    "\n",
    "for i in range(test_ds.shape[0]):\n",
    "    image, points = prep_image(train_ds.iloc[i])\n",
    "    input_image = tf.cast(image, dtype=tf.int32)\n",
    "    testX.append(input_image)\n",
    "    testY.append(points)\n",
    "\n",
    "trainX_ = tf.convert_to_tensor(trainX, dtype=tf.float32) / 255\n",
    "trainY_ = tf.convert_to_tensor(trainY, dtype=tf.float32)\n",
    "\n",
    "testX_ = tf.convert_to_tensor(testX, dtype=tf.float32) / 255\n",
    "testY_ = tf.convert_to_tensor(testY, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "def build(size):\n",
    "    model = Sequential()\n",
    "    inputShape = (size, size, 3)\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "                     input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    # model.add(Activation(\"relu\"))\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(cfg.OUTPUTS))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(load_latest = False):\n",
    "    model = build(194)\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.Huber(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    if load_latest:\n",
    "        checkpoint_dir = os.path.dirname(cfg.CHECKPOINT_PATH)\n",
    "        latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        model.load_weights(latest)\n",
    "       \n",
    "    batch_size = 77\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=cfg.CHECKPOINT_PATH,\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_freq=5*batch_size)\n",
    "    return model, cp_callback\n",
    "\n",
    "\n",
    "def load_model(path):\n",
    "    model = tf.keras.models.load_model(path)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    loss, acc = model.evaluate(testX_, testY_, verbose=2)\n",
    "    print(f'Model, accuracy: {acc*100:5.2f}%')\n",
    "\n",
    "def save_model(model, path):\n",
    "    model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, cp_callback = get_model()\n",
    "\n",
    "model.fit(trainX_, \n",
    "          trainY_,\n",
    "          epochs=10,\n",
    "          validation_data=(testX_, testY_),\n",
    "          callbacks=[cp_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[110 112 113]\n",
      "  [112 114 115]\n",
      "  [110 112 113]\n",
      "  ...\n",
      "  [ 33  37  41]\n",
      "  [ 29  33  39]\n",
      "  [ 23  27  32]]\n",
      "\n",
      " [[110 112 113]\n",
      "  [111 113 114]\n",
      "  [111 112 113]\n",
      "  ...\n",
      "  [ 24  29  32]\n",
      "  [ 20  24  29]\n",
      "  [ 20  24  29]]\n",
      "\n",
      " [[110 112 113]\n",
      "  [111 112 114]\n",
      "  [110 112 114]\n",
      "  ...\n",
      "  [ 22  26  32]\n",
      "  [ 27  31  37]\n",
      "  [ 24  27  33]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[115 117 118]\n",
      "  [115 117 118]\n",
      "  [115 117 118]\n",
      "  ...\n",
      "  [ 69  90 121]\n",
      "  [ 78 102 132]\n",
      "  [ 84 108 138]]\n",
      "\n",
      " [[115 117 118]\n",
      "  [115 117 118]\n",
      "  [115 117 118]\n",
      "  ...\n",
      "  [ 75  96 127]\n",
      "  [ 82 106 136]\n",
      "  [ 89 113 143]]\n",
      "\n",
      " [[116 118 119]\n",
      "  [115 117 118]\n",
      "  [115 117 118]\n",
      "  ...\n",
      "  [ 82 103 134]\n",
      "  [ 87 110 141]\n",
      "  [ 93 117 147]]]\n"
     ]
    }
   ],
   "source": [
    "def predictor(model, image_path, size):\n",
    "    image = cv2.imread(image_path)\n",
    "    # dims = image.shape\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    dimsCrop = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        image = image[y:y + h, x:x + w]\n",
    "        dimsCrop.append([x,y,w,h])\n",
    "    \n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((size, size))\n",
    "    image = np.array(image)\n",
    "    \n",
    "    # predict\n",
    "    input_image = tf.cast(image, dtype=tf.float32) / 255\n",
    "    input_image = tf.expand_dims(input_image, axis=0)\n",
    "    res = model.predict(input_image)\n",
    "\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    for i in range(0, 136, 2):\n",
    "        x_.append(int(res[0][i] * size * (dimsCrop[0][3] / size) + dimsCrop[0][0]))\n",
    "        y_.append(int(res[0][i+1]* size * (dimsCrop[0][3] / size) + dimsCrop[0][1]))\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    for i in range(68):\n",
    "        image = cv2.circle(image, (x_[i], y_[i]), 1, (0, 0, 255), int(image.shape[1] * 0.006))\n",
    "    cv2.imwrite('pic.jpeg', image)\n",
    "    return res\n",
    "    \n",
    "\n",
    "# resnew = predictor(model, 'data\\data\\InitialDS\\\\1 (10).jpg', 194)\n",
    "resold = predictor(nm, 'data\\data\\InitialDS\\\\0 (19).jpg', 194)\n",
    "# print(resold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "nm = load_model('best_model_so_far194.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd7bb9ae62c98bc132fa2013d02efcfcb1013235298d363be733d2a2a3688bc4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
