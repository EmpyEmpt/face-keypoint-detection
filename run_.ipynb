{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image:\n",
    "    filename: str\n",
    "    width_height: int\n",
    "    TL: list\n",
    "    BR: list\n",
    "    points: list\n",
    "\n",
    "    def __init__(self, fn, tlx, tly, brx, bry, points):\n",
    "        # print(f'fucking {fn}')\n",
    "        self.filename = fn\n",
    "        self.TL = [tlx, tly]\n",
    "        self.BR = [brx, bry]\n",
    "        self.points = points\n",
    "        self.width_height = self.BR[0] - self.TL[0]\n",
    "\n",
    "    def to_list(self):\n",
    "        return [self.filename, self.TL, self.width_height, self.points]\n",
    "\n",
    "    def read_all(path):\n",
    "        file = open(path)\n",
    "        csvreader = csv.reader(file)\n",
    "        all = []\n",
    "        i = 0\n",
    "        for row in csvreader:\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            ye = True\n",
    "            for value in row:\n",
    "                if value.startswith('-'):\n",
    "                    ye = False\n",
    "                    break\n",
    "            if ye:\n",
    "                all.append(image(row[0], int(row[1]), int(\n",
    "                    row[2]), int(row[3]), int(row[5]), row[5:]).to_list())\n",
    "        file.close()\n",
    "        return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    \"\"\"Splits a panda dataframe in two.\"\"\"\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop_face(image, image_path, x, y, w, h):\n",
    "#     roi_color = image[y:y + h, x:x + w]\n",
    "#     if image_path.endswith('png'):\n",
    "#         cv2.imwrite('data\\data\\croped\\\\' + str(w) +\n",
    "#                 str(h) + '_faces.png', roi_color)\n",
    "#         return roi_color, 'data\\data\\croped\\\\' + str(w) + str(h) + '_faces.png'\n",
    "        \n",
    "#     if image_path.endswith('jpg') or image_path.endswith('jpeg'):\n",
    "#         cv2.imwrite('data\\data\\croped\\\\' + str(w) +\n",
    "#                 str(h) + '_faces.jpg', roi_color)\n",
    "#         return roi_color, 'data\\data\\croped\\\\' + str(w) + str(h) + '_faces.jpg'\n",
    "def crop_face(image, image_path, x, y, w, h):\n",
    "    roi_color = image[y:y + h, x:x + w]\n",
    "    return roi_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(dp):\n",
    "    image_path = dp[0]\n",
    "    bb = dp[1]\n",
    "    wh = dp[2]\n",
    "    points = dp[3]\n",
    "    # print(image_path)\n",
    "    # crop out face from image\n",
    "    image = cv2.imread(cfg.IMAGES_PATH + image_path)\n",
    "    # image, path = crop_face(image, image_path,\n",
    "    #                     int(bb[0]), int(bb[1]), int(wh), int(wh))\n",
    "    image = crop_face(image, image_path, int(bb[0]), int(bb[1]), int(wh), int(wh))\n",
    "    path = 'data\\data\\\\tmp\\\\' + image_path\n",
    "    cv2.imwrite(path, image)\n",
    "    \n",
    "    # resize image to xxx * xxx\n",
    "    image = Image.open(path)\n",
    "    image = image.resize((194, 194))\n",
    "\n",
    "    path = 'data\\data\\\\croped\\\\' + image_path\n",
    "    image.save(path)\n",
    "\n",
    "    # image = cv2.resize(image, (wh, wh), interpolation=cv2.INTER_AREA)\n",
    "    # path = 'data\\data\\croped\\\\' + image_path\n",
    "    # cv2.imwrite(path, image)\n",
    "\n",
    "\n",
    "    # save resize ratio\n",
    "    crop_r = cfg.CROP_SIZE / wh\n",
    "\n",
    "    # resize points using resize ratio\n",
    "    for point in points:\n",
    "        point = float(point)\n",
    "        point = point * crop_r\n",
    "\n",
    "    # convert points to relative [0.0 -> 1]\n",
    "    npo = []\n",
    "    for point in points:\n",
    "        point_ = float(point) / wh\n",
    "        npo.append(point_)\n",
    "    # for i in range(0, 135, 2):\n",
    "    #     point1 = float(points[i]) / wh\n",
    "    #     point2 = float(points[i+1]) / wh\n",
    "    #     npo.append([point1, point2])\n",
    "    \n",
    "\n",
    "    # (should I really convert it to tensor?)\n",
    "    npo = tf.convert_to_tensor(npo, dtype=tf.float32)\n",
    "\n",
    "    # PROFIT?\n",
    "    return path, npo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (194, 194, 3)\n",
    "output_shape = (136, )\n",
    "ds = image.read_all(cfg.LABELS_PATH)\n",
    "ds = pd.DataFrame(ds)\n",
    "train_ds, test_ds = split_dataset(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "testX = []\n",
    "testY = []\n",
    "\n",
    "for i in range(train_ds.shape[0]):\n",
    "    path, points = prep_image(train_ds.iloc[i])\n",
    "    input_image = tf.io.read_file(path)\n",
    "    input_image = tf.image.decode_image(input_image)\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    trainX.append(input_image)\n",
    "    trainY.append(points)\n",
    "\n",
    "    # VERY TEMPOPARY BREAK\n",
    "    # break\n",
    "\n",
    "for i in range(test_ds.shape[0]):\n",
    "    path, points = prep_image(train_ds.iloc[i])\n",
    "    input_image = tf.io.read_file(path)\n",
    "    input_image = tf.image.decode_image(input_image)\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    testX.append(input_image)\n",
    "    testY.append(points)\n",
    "\n",
    "    # VERY TEMPOPARY BREAK\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_ = tf.convert_to_tensor(trainX, dtype = tf.int32)\n",
    "trainY_ = tf.convert_to_tensor(trainY, dtype = tf.float32)\n",
    "\n",
    "testX_ = tf.convert_to_tensor(testX, dtype=tf.int32)\n",
    "testY_ = tf.convert_to_tensor(testY, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_vggface.vggface import VGGFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 194, 194, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 194, 194, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 194, 194, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 97, 97, 64)        0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 97, 97, 128)       73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 97, 97, 128)       147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 48, 48, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 48, 48, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 48, 48, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 48, 48, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 24, 24, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 24, 24, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 24, 24, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 24, 24, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 2048)              37750784  \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 512)               1049088   \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 136)               69768     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,584,328\n",
      "Trainable params: 53,584,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGGFace(include_top=False, model= 'vgg16',input_shape=(\n",
    "    cfg.CROP_SIZE, cfg.CROP_SIZE, 3))\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "x = tf.keras.layers.Flatten(name='flatten')(last_layer)\n",
    "x = tf.keras.layers.Dense(2048, activation='relu', name='fc6')(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu', name='fc7')(x)\n",
    "out = tf.keras.layers.Dense(136, activation='relu', name='fc8')(x)\n",
    "model = tf.keras.Model(vgg_model.input, out)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsolutePercentageError(\n",
    "                  name='mean_absolute_percentage_error'\n",
    "              ),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX_, trainY_, epochs=10,\n",
    "          validation_data=(testX_, testY_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smallervggnet import SmallerVGGNet\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "p_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1)\n",
    "model = SmallerVGGNet.build()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsolutePercentageError(\n",
    "                  name='mean_absolute_percentage_error'\n",
    "              ),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX_, \n",
    "          trainY_,\n",
    "          epochs=100,\n",
    "          validation_data=(testX_, testY_),\n",
    "          callbacks=[cp_callback])\n",
    "model.save('saved_model/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(testX_, testY_, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd7bb9ae62c98bc132fa2013d02efcfcb1013235298d363be733d2a2a3688bc4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
