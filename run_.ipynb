{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_whole_csv(path):\n",
    "    file = open(path)\n",
    "    csvreader = csv.reader(file)\n",
    "    all = []\n",
    "    next(csvreader, None)\n",
    "    for row in csvreader:\n",
    "        ye = True\n",
    "        for value in row:\n",
    "            if value.startswith('-'):\n",
    "                ye = False\n",
    "                break\n",
    "        if ye:\n",
    "            all.append([row[0], [int(row[1]), int(row[2])],\n",
    "                       int(row[3]) - int(row[1]), row[5:]])\n",
    "    file.close()\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(image, x, y, w, h):\n",
    "    image = image[y:y + h, x:x + w]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(dp):\n",
    "    wh = int(dp[2])\n",
    "    points = [(float(a) / wh) for a in dp[3]]\n",
    "    # crop out face from image\n",
    "    image = cv2.imread(cfg.IMAGES_PATH + dp[0])\n",
    "    image = crop_face(image, int(dp[1][0]), int(dp[1][1]), wh, wh)\n",
    "\n",
    "    # resize image to xxx * xxx\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((cfg.CROP_SIZE, cfg.CROP_SIZE))\n",
    "    image = np.array(image)\n",
    "\n",
    "    # (should I really convert it to tensor?)\n",
    "    points = tf.convert_to_tensor(points, dtype=tf.float32)\n",
    "\n",
    "    # PROFIT?\n",
    "    return image, points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = read_whole_csv(cfg.LABELS_PATH)\n",
    "ds = pd.DataFrame(ds)\n",
    "train_ds, test_ds = split_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "trainX = []\n",
    "trainY = []\n",
    "testX = []\n",
    "testY = []\n",
    "\n",
    "for i in range(train_ds.shape[0]):\n",
    "    image, points = prep_image(train_ds.iloc[i])\n",
    "    input_image = tf.cast(image, dtype=tf.int32)\n",
    "    trainX.append(input_image)\n",
    "    trainY.append(points)\n",
    "\n",
    "for i in range(test_ds.shape[0]):\n",
    "    image, points = prep_image(train_ds.iloc[i])\n",
    "    input_image = tf.cast(image, dtype=tf.int32)\n",
    "    testX.append(input_image)\n",
    "    testY.append(points)\n",
    "\n",
    "trainX_ = tf.convert_to_tensor(trainX, dtype=tf.float32) / 255\n",
    "trainY_ = tf.convert_to_tensor(trainY, dtype=tf.float32)\n",
    "\n",
    "testX_ = tf.convert_to_tensor(testX, dtype=tf.float32) / 255\n",
    "testY_ = tf.convert_to_tensor(testY, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "def build_old(image_size):\n",
    "    model = Sequential()\n",
    "    inputShape = (image_size, image_size, 3)\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "                     input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    # model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    # model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    # model.add(Activation(\"relu\"))\n",
    "    # model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    # model.add(Activation(\"relu\"))\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(cfg.OUTPUTS))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build(size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # model.add(BatchNormalization(input_shape=(size, size, 3)))\n",
    "\n",
    "    model.add(Conv2D(24, (5, 5), padding='same',\n",
    "              input_shape=(size, size, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(36, (5, 5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "              strides=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(48, (5, 5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "              strides=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "              strides=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(136))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(load_latest = False):\n",
    "    model = build(cfg.CROP_SIZE)\n",
    "\n",
    "    # old\n",
    "    # model.compile(optimizer='adam',\n",
    "    #             loss=tf.keras.losses.Huber(),\n",
    "    #             metrics=['accuracy'])\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    if load_latest:\n",
    "        checkpoint_dir = os.path.dirname(cfg.CHECKPOINT_PATH)\n",
    "        latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        model.load_weights(latest)\n",
    "       \n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = tf.keras.models.load_model(path)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    loss, acc = model.evaluate(testX_, testY_, verbose=2)\n",
    "    print(f'Model, accuracy: {acc*100:5.2f}%')\n",
    "\n",
    "def save_model(model, path):\n",
    "    model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 43s 547ms/step - loss: 1.2793e-04 - accuracy: 0.8916 - val_loss: 1.1535e-04 - val_accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x239e28006d0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 78\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=cfg.CHECKPOINT_PATH,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5*batch_size)\n",
    "\n",
    "model.fit(trainX_, \n",
    "          trainY_,\n",
    "          epochs=1,\n",
    "          validation_data=(testX_, testY_),\n",
    "          shuffle=True,\n",
    "          callbacks=[cp_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, 'models/x128NA-89.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 3s - loss: 1.1535e-04 - accuracy: 0.8938 - 3s/epoch - 144ms/step\n",
      "Model, accuracy: 89.38%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testX_, testY_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(model, image_path, size):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faceCascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "\n",
    "    # dimsCrop = [[110, 110, 300, 300]]\n",
    "    dimsCrop = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        image = image[y:y + h, x:x + w]\n",
    "        dimsCrop.append([x,y,w,h])\n",
    "        \n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((size, size))\n",
    "    image = np.array(image)\n",
    "    \n",
    "    # predict\n",
    "    input_image = tf.cast(image, dtype=tf.float32) / 255\n",
    "    input_image = tf.expand_dims(input_image, axis=0)\n",
    "    res = model.predict(input_image)\n",
    "    # print(res)\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    for i in range(0, 136, 2):\n",
    "        x_.append(int(res[0][i] * size * (dimsCrop[0][3] / size) + dimsCrop[0][0]))\n",
    "        y_.append(int(res[0][i+1]* size * (dimsCrop[0][3] / size) + dimsCrop[0][1]))\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    for i in range(68):\n",
    "        image = cv2.circle(image, (x_[i], y_[i]), 1, (0, 0, 255), int(image.shape[1] * 0.006))\n",
    "    cv2.imwrite('pic.jpeg', image)\n",
    "    \n",
    "    \n",
    "\n",
    "# predictor(model, 'data\\data\\InitialDS\\\\0 (13).jpg', 128)\n",
    "predictor(model, 'data\\data\\InitialDS\\\\0 (19).jpg', 128)\n",
    "# predictor(model, 'ay.JPG', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('models\\\\x128-92.78.h5')\n",
    "model = load_model('models\\\\x128NA-89.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my implementation\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    size = 128\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.copyMakeBorder(frame, 50, 50, 50, 50, cv2.BORDER_CONSTANT)\n",
    "    gray = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    dimsCrop = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        image = frame[y:y + h, x:x + w]\n",
    "        dimsCrop.append([x, y, w, h])\n",
    "        cv2.rectangle(img=frame, pt1=(x, y), pt2=(\n",
    "            x+w, y+h), color=(0, 255, 0), thickness=4)\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((size, size))\n",
    "    image = np.array(image)\n",
    "\n",
    "    # predict\n",
    "    input_image = tf.cast(image, dtype=tf.float32) / 255\n",
    "    input_image = tf.expand_dims(input_image, axis=0)\n",
    "    res = model.predict(input_image)\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    if len(dimsCrop) > 0:\n",
    "        for i in range(0, 136, 2):\n",
    "            x_.append(\n",
    "                int(res[0][i] * size * (dimsCrop[0][3] / size) + dimsCrop[0][0]))\n",
    "            y_.append(int(res[0][i+1] * size *\n",
    "                    (dimsCrop[0][3] / size) + dimsCrop[0][1]))\n",
    "\n",
    "        for i in range(68):\n",
    "            image = cv2.circle(frame, (x_[i], y_[i]), 1,\n",
    "                            (0, 0, 255), int(image.shape[1] * 0.006))\n",
    "    cv2.imshow(winname=\"Face\", mat=frame)\n",
    "    if cv2.waitKey(delay=1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# somewhat real (not mine tho)\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        x1 = face.left()  # left point\n",
    "        y1 = face.top()  # top point\n",
    "        x2 = face.right()  # right point\n",
    "        y2 = face.bottom()  # bottom point\n",
    "\n",
    "        landmarks = predictor(image=gray, box=face)\n",
    "        for n in range(0, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(img=frame, center=(x, y), radius=3,\n",
    "                       color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "    cv2.imshow(winname=\"Face\", mat=frame)\n",
    "    if cv2.waitKey(delay=1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd7bb9ae62c98bc132fa2013d02efcfcb1013235298d363be733d2a2a3688bc4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
